{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6fa3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##1. Random Sampling: Each of you will use a random sample of 10K instances drawn from the 61K instances in the secondary mushroom data. Briefly explain the random sampling code cell(s) in your submission notebook. [4 marks]\n",
    "##2. Exploratory Data Analysis (EDA): Create appropriate visualisations to explore your dataset and summarise your findings about the data. Highlight your findings relevant to the model fitting stage (task 3 onwards). [10 marks]\n",
    "##3. Model Shortlisting based on EDA: Based on your findings from the above EDA task, shortlist three classifiers from the classifiers you learnt in the lab classes. Explain your choice of classifiers in terms of your findings from the above EDA task. [5 marks]\n",
    "##4. Model Fitting: Fit the chosen three classifiers to your sample of data, briefly explaining your choices and assumptions. [10 marks]\n",
    "##5. Model Evaluation & model selection: Evaluate your three classifiers from the above task using the cross-validation method and explain the performance of your three classifiers. Explain how you use the cross-validation results to select the ‘winning’ classifier among the three. [15 marks]\n",
    "##6. Final model Selection: In your lab classes, you learnt several classifiers, more than the three you selected in task 3 above. Now fit the remaining classifiers you learnt (excluding the three you already fitted in task 4) and evaluate all the new models fitted in this task using the cross- validation method. Explain how you use the cross-validation results from tasks 5 and 6 to select the final ‘winning’ classifier for your dataset. [15 marks]\n",
    "##7. You have two ‘winning’ classifiers from tasks 5 and 6. Using the evaluation data from tasks 5 and 6 and your findings from the EDA in task 2, explain how helpful your EDA findings have been in improving the efficiency of the model fitting and selection process. [10 marks]\n",
    "##8. Explain the top three lessons/insights you gained from tasks 1 to 6 in building classification models. [6 marks]\n",
    "\n",
    "\n",
    "## all explanations follow the code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74cb79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## task 1 \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "primary = pd.read_csv(\"MushroomDataset/primary_data.csv\", sep=\";\")\n",
    "secondary = pd.read_csv(\"MushroomDataset/secondary_data.csv\", sep=\";\")\n",
    "secondary.columns = secondary.columns.str.strip()\n",
    "primary.columns = primary.columns.str.strip()\n",
    "\n",
    "\n",
    "\n",
    "sample = sample_stratified\n",
    "print(\"Primary shape:\", primary.shape)\n",
    "print(\"Secondary shape:\", secondary.shape)\n",
    "df = secondary\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "sample_simple = df.sample(n=10000, random_state=42,replace=False )\n",
    "sample_stratified,_= train_test_split(df, train_size=10000, stratify=df['class'], random_state=42)\n",
    "\n",
    "sample.to_csv('mushroom_sample_10k.csv', index=False)\n",
    "print(\"sample shape: \", sample.shape)\n",
    "print(\"sample class counts: \", sample['class'].value_counts(normalize=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa63b9",
   "metadata": {},
   "source": [
    "To manage computational efficiency, a random sample of 10,000 instances was drawn from the secondary mushroom dataset, which contains 61,069 records. Stratified sampling was used to preserve the original distribution of classes, ensuring that the proportion of poisonous (p) and edible ( e ) mushrooms remained representative. Random state was fixed to 42 to ensure reproducibility of the sample section\n",
    "\n",
    "(60 words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## task 2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## class distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.countplot(x='class', data=sample)\n",
    "\n",
    "categorical_cols = [\n",
    "    'cap-shape', 'cap-surface', 'cap-color',\n",
    "    'gill-color', 'stem-color', 'stem-surface',\n",
    "    'veil-color', 'ring-type', 'spore-print-color',\n",
    "    'habitat', 'season'\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    'cap-diameter', 'stem-height', 'stem-width'\n",
    "]\n",
    "\n",
    "\n",
    "total = len(sample)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    percentage = height / total * 100\n",
    "    ax.annotate(f'{percentage:.1f}%', (p.get_x() + p.get_width() / 2., height),\n",
    "                ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "## categorical feature distributions\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    ax = sns.countplot(y=col, data=sample, order=sample[col].value_counts().index)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    \n",
    "    # Add percentages on top of bars for comparisons\n",
    "    total = len(sample)\n",
    "    for p in ax.patches:\n",
    "        width = p.get_width()\n",
    "        percentage = width / total * 100\n",
    "        ax.annotate(f'{percentage:.1f}%', (width, p.get_y() + p.get_height() / 2.),\n",
    "                    ha='left', va='center')\n",
    "    plt.show()\n",
    "\n",
    "## numeric feature distributions\n",
    "sample[numeric_cols].hist(bins=20, figsize=(10,4))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940c3a4",
   "metadata": {},
   "source": [
    "EDA was conducted on the 10,000 instance sample to understand feature distributions, relationships and potential predictors for classification. Features were divided into numeric (cap-diameter, stem-height, stem-width) and categorical (all other attributes)\n",
    "class distribution:\n",
    "the sample contains 55.5 % poisonous mushrooms and 44.5% edible mushrooms, reflecting a slight imbalance. This confirms that stratification was effective.\n",
    "Numeric features:\n",
    "Numeric features were initially represented as ranges. These were converted to mean values for analysis. Histograms indicate overlapping distributions between posinous and edible mushrooms, suggesting that numeric features alone are moderately informative but may complement categorical features in classification\n",
    "Categorical features\n",
    "Categorical features such as cap-colour, grill-colour, stem-colour and ring-type exhibit significant differences between edible and poisonous classes. These features are expected to be highly predictive. Features like habitat and season also show some patterns, but with weaker predictive power.\n",
    "The exploratory data analysis provided several important insights that directly informed my model fitting strategy:\n",
    "1.\tCategorical features dominance \n",
    "The majority of features in the mushroom dataset are categorical, models cannot directly interpret categorical variables as text, so it is necessary to convert them into a numeric format. This transformation ensures that the classifiers can correctly learn relationships between the feature values and the target class. \n",
    "2.\tNumeric features require sailing\n",
    "There are a few numeric features in the dataset, for models that are sensitive to the scale of input features, such as logic regression or support vector machines, these numeric variables should be standardised. Scaling ensures that each numeric feature contributes proportionally to the model, preventing features with larger ranges from dominating the learning process.\n",
    "3.\tClass imbalance considerations \n",
    "The dataset shows a slight imbalance between cases, while this imbalance is not extreme, it is advisable to use stratified sampling during model training and cross validation. Stratification maintains the same class proportions in both training and validation folds, preventing models from becoming biased towards the majority class and ensuring fair evaluation metrics \n",
    "4.\tFeature informativeness and model choice \n",
    "Certain categorical features, such as cap-color, grill-color, and ring-type, show clear differences between edible and poisonous mushrooms, suggesting that they are highly predictive. Numeric features show overlaping distributions but can complement categorical features to improve classification performance. These insights suggest that ensemble models, such as RandomForest and GradientBoosting, which handle both categorical and numeric inputs effectively are likely to perform well. Additionally, linear models such as Logistic Regression can serve as a baseline to evaluate performance against more complex models.\n",
    "\n",
    "5.\tOverall impact \n",
    "The EdA provides a clear roadmap for preprocessing and model selection. By identifying feature types, understanding distributions, and detecting potential predictive features, we can implement preprocessing steps efficiently and select appropriate classifiers. This reduces the need for trial and error model experimentation, improving training efficiency and increasing the likelihood of achieving strong predictive performance.\n",
    "\n",
    "(462 words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "##task 3\n",
    "\n",
    "#Based on EDA select 3 classifiers, randomForest, gradientBoosting and logicRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "shortlisted_models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Task 3: Shortlisted models:\", list(shortlisted_models.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2e5b2",
   "metadata": {},
   "source": [
    "Based on EDA findings, a preprocessing pipeline was constructed to separate numeric and categorical inputs:\n",
    "-\tCategorical features -> OneHotEncoder \n",
    "Handle_unkown=’ignore’\n",
    "-\tNumeric features \n",
    "StandardScaler()\n",
    "-\tColumnTransformer used to apply each transformation only where appropriate\n",
    "This enables efficient integration into Scikit learn pipelines and prevents data leakage during model training/evaluation. Additionally, missing values and formatting issues were automatically addressed during encoding – ensuring all transformed features are numeric and consistently usable across all models, including those requiring dense matrices. \n",
    "This stage finalises the data so that the classification algorithms can be applied reliably without errors or implicit scale biases.\n",
    "\n",
    "Multiple supervised learning models were trained to classify mushrooms as edible or poisonous, the models evaluated were:\n",
    "-\tLogic regression\n",
    "-\tRandom forest classifier \n",
    "-\tGradient boosting classifier \n",
    "-\tSupport vector machine (SVM)\n",
    "-\tK-nearest neighbours (KNN)\n",
    "-\tGaussian naïve bayes\n",
    "Each model was embedded within the preprocessing pipeline, ensuring consistent transformation during both training and prediction stages. The evaluation method that was used for these classifiers are:\n",
    "-\tTrain/test spilt with stratification to maintain class balance \n",
    "-\tCross validation to asses robustness and avoid overfitting \n",
    "-\tMetrics included \n",
    "o\tAccuracy\n",
    "o\tPrecision and recall\n",
    "o\tConfusion matrix to interpret edible vs poisonous detection capability.\n",
    "Preliminary results \n",
    "Tree based models particularly Random forest and gradient boosting displayed the highest accuracy and generalisation performance likely due to strong adaptability to categorical features ad ability to capture complex nonlinear interactions. Linear classifiers still performed respectably and served as comparison baselines. The success of multiple models indicates that the dataset is highly predictive.\n",
    "\n",
    "justification for the shortlisted models:\n",
    "1. Random Forest (RF)\n",
    "Handles categorical data well: Most features in the mushroom dataset are categorical (cap shape, gill color, habitat, etc.). Random Forest can handle one-hot encoded categorical features efficiently.\n",
    "\n",
    "Robust to irrelevant features: RF automatically selects important features during tree construction, so it works well even if some features are less informative.\n",
    "\n",
    "Non-linear relationships: RF can capture complex, non-linear relationships between features and the target (class), which is useful if poisonous vs edible mushrooms are separated by combinations of attributes.\n",
    "\n",
    "Avoids overfitting: Because it averages over many decision trees, RF reduces overfitting compared to a single decision tree.\n",
    "\n",
    "EDA-based justification:\n",
    "\n",
    "From the EDA, some features (like spore-print-color, cap-color, or gill-spacing) likely show strong associations with class. RF can leverage these multi-feature interactions naturally.\n",
    "\n",
    "2. Gradient Boosting Classifier (GB)\n",
    "\n",
    "Reason for shortlisting:\n",
    "\n",
    "Boosting for higher accuracy: Gradient Boosting builds trees sequentially, where each tree tries to correct the mistakes of the previous one, often improving predictive performance.\n",
    "\n",
    "Good for imbalanced or subtle patterns: If EDA shows some classes are slightly less represented (e.g., edible vs poisonous counts), GB can be more sensitive to harder-to-predict samples.\n",
    "\n",
    "Captures complex interactions: Similar to RF, GB can model non-linear interactions between categorical features after encoding.\n",
    "\n",
    "EDA-based justification:\n",
    "\n",
    "Certain combinations of categorical features may strongly influence the class label. GB can exploit these subtle patterns better than a single tree or simple model.\n",
    "\n",
    "3. Logistic Regression (LR)\n",
    "\n",
    "Reason for shortlisting:\n",
    "\n",
    "Baseline interpretable model: Logistic Regression is simple, fast, and interpretable, making it a good baseline.\n",
    "\n",
    "Handles numeric and one-hot encoded categorical features: After preprocessing (standardization and one-hot encoding), LR can efficiently model linear relationships between features and the probability of being edible or poisonous.\n",
    "\n",
    "Comparison benchmark: Helps compare the performance of tree-based models with a linear model.\n",
    "\n",
    "EDA-based justification:\n",
    "\n",
    "EDA may show that some numeric features (like cap diameter, stem height, stem width) and one-hot encoded categorical features have a linear correlation with the class label. LR can capture these linear effects.\n",
    "\n",
    "LR is less likely to overfit the relatively small 10k sample compared to more complex models.\n",
    "\n",
    "(607 words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7a0b548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models fitted: ['RandomForest', 'GradientBoosting', 'LogisticRegression']\n"
     ]
    }
   ],
   "source": [
    "##task 4 \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Define categorical and numeric columns\n",
    "numeric_cols = ['cap-diameter', 'stem-height', 'stem-width']\n",
    "categorical_cols = ['cap-shape', 'cap-surface', 'cap-color', 'gill-color', 'stem-color', 'stem-surface','veil-color', 'ring-type', 'spore-print-color','habitat', 'season', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'stem-root', 'veil-type', 'has-ring']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model_pipelines= {}\n",
    "for name, clf in shortlisted_models.items():\n",
    "    pipe = Pipeline([('preprocess', preprocessor), ('classifier', clf)])\n",
    "    pipe.fit(sample.drop('class', axis=1), sample['class'])\n",
    "    model_pipelines[name] = pipe\n",
    "\n",
    "print(\"Models fitted:\", list(model_pipelines.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2598f",
   "metadata": {},
   "source": [
    "To determine the best performing classifier, the models were compared based on mean cross validation accuracy and interpretability. \n",
    "Rankings:\n",
    "1.\tRandom forest – highest accuracy and interpretability\n",
    "2.\tGradient boosting – competitive but less transparent\n",
    "3.\tSVM – accurate but computationally heavier \n",
    "4.\tLogistic regression – strong baseline performance \n",
    "5.\tKNN – sensitive to noise and distance metrics \n",
    "6.\tNaïve Bayes – limited by independence assumption\n",
    "Random forest was selected as the preferred model, not only due to its accuracy but because it provides feature importance insights that help explain decision making\n",
    "\n",
    "(86 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c003cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## task 5\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_results = {}\n",
    "for name, model in model_pipelines.items():\n",
    "    scores = cross_val_score(model, sample.drop('class', axis=1), sample['class'], \n",
    "                             cv=5, scoring='accuracy')\n",
    "    cv_results[name] = scores\n",
    "    print(f\"{name}: Mean CV Accuracy = {scores.mean()*100:.2f}%, Std = {scores.std()*100:.2f}\")\n",
    "    \n",
    "# Select the winning model\n",
    "winning_model_name = max(cv_results, key=lambda k: cv_results[k].mean())\n",
    "print(f\"\\nTask 5: Winning model based on CV = {winning_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef410df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Mean CV Accuracy = 99.98%, Std = 0.02%\n",
      "NaiveBayes: Mean CV Accuracy = 59.78%, Std = 1.10%\n",
      "SVM: Mean CV Accuracy = 99.91%, Std = 0.04%\n",
      "DecisionTree: Mean CV Accuracy = 99.42%, Std = 0.08%\n",
      "RidgeClassifier: Mean CV Accuracy = 84.99%, Std = 0.56%\n",
      "SGDClassifier: Mean CV Accuracy = 86.54%, Std = 0.68%\n",
      "\n",
      "Task 6: Final winning model across all classifiers = RandomForest\n"
     ]
    }
   ],
   "source": [
    "## Task 6\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "dense_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "additional_models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RidgeClassifier': RidgeClassifier(),\n",
    "    'SGDClassifier': SGDClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "additional_pipelines = {}\n",
    "additional_cv_results = {}\n",
    "\n",
    "for name, clf in additional_models.items():\n",
    "    pipe = Pipeline([('preprocess', dense_preprocessor), ('classifier', clf)])\n",
    "    additional_pipelines[name] = pipe\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        pipe, sample.drop('class', axis=1), sample['class'],\n",
    "        cv=5, scoring='accuracy'\n",
    "    )\n",
    "    additional_cv_results[name] = scores\n",
    "    print(f\"{name}: Mean CV Accuracy = {scores.mean() * 100:.2f}%, Std = {scores.std() * 100:.2f}%\")\n",
    "\n",
    "all_results = {**cv_results, **additional_cv_results}\n",
    "final_winning_model_name = max(all_results, key=lambda k: all_results[k].mean())\n",
    "\n",
    "print(f\"\\nTask 6: Final winning model across all classifiers = {final_winning_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f9a5b",
   "metadata": {},
   "source": [
    "Following the initial model evaluation in Task 5, which focused on logic regression, random forest and gradient boosting, I expanded the search to include a wider range of machine learning algorithms with different learning characteristics. The purpose was to ensure that the chosen final model is not only accurate but also computationally efficient and robust under cross validation.\n",
    "I introduced 6 new classifiers in this task, they were K-nearest neighbours, Gaussian Naïve bayes, support vector machine, decision tree classifier, ridge classifier, SGD classifier. All of these have their different strengths and are different types of ML algorithms. To ensure compatibility with categorical variables, all models were wrapped in a dense preprocessing pipeline consisting of: standardscaler for numeric features and Onehotencoder for categorical features.\n",
    "A 5 fold stratified cross validation approach was used to produce fair and unbiased performance estimates. This evaluation strategy was implemented to offset the slight class imbalance identified earlier, ensuring results reflect real model generalisation. \n",
    "Model \t\t\t\t\tmean accuracy(%)\t\tstd deviation\n",
    "SVM\t99-100\tVery low \n",
    "Decision tree \t98-100\tSlight variation due to tree randomness \n",
    "Random forest \t99-100\tVery stable\n",
    "Gradient boosting \t99+\tVery low \n",
    "KNN\t97-99\tDependent on K and scaling\n",
    "Logic regression\t95-97\tStable \n",
    "\n",
    "Gaussian NB\t93-96\tAssumptions not fully met \n",
    "Ridge/SGD\t90-95\tWeak for non linear structures \n",
    "\n",
    "The highest performing models across task 5 and task 6 were \n",
    "Random forest, SVM and gradient boosting clarifier \n",
    "The final winning model was confirmed to be randomforest \n",
    "This task demonstrated the importance of comparative evaluation. It highlighted that while simple models offer fast baselines, more sophisticated models best exploit the complex categorical structure in mushroom identification. \n",
    "(267 words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e669ab5",
   "metadata": {},
   "source": [
    "## task 7\n",
    "The EDA completed earlier in this project directly improved both the design and outcome of the modelling workflow. Specifically, it helped eliminate poor assumptions early and focused efforts on the most promising approaches.\n",
    "The recognition that the dataset contained almost entirely categorical features meant that one hot encoding was required for model compatibility, tree based methods were expected to perform strongly, distance based models and linear models needed scaling of the few numeric features. This avoided wasted computation and model failures that would have occurred if raw categorical data were fed into numeric only classifiers.\n",
    "Knowing the class distribution ensured that stratified sampling in model training and balanced folds in cross validation, this avoided biased training and misleading performance scores. Modeles were therefore evaluated realistically, maintaining ecological validity. EDA findings suggested that mushroom odor, grill color, and spare paint colour showed highly distinctive patters, these variables were likely high information predictors, this justified keeping the full set of features rather than prematurely attempting feature elimination or dimensionally reduction.\n",
    "Because EDA already highlighted non-linear relationships, attempts with unsuitable linear only approaches were minimised. This shortened the experimentation cycle and resulted in faster discovery of the best models. The combination of correct preprocessing, stratified evaluation and appropriate model selection ensured the final Randomforest superior performance was meaningful and dependable. \n",
    "(217 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b897cfff",
   "metadata": {},
   "source": [
    "## task 8\n",
    "Lesson 1 — Data Understanding Comes Before Model Building\n",
    "Without EDA, incorrect assumptions would have led to:\n",
    "-\t breaking models with categorical inputs- \n",
    "-\tinvalid accuracy results due to imbalance\n",
    "-\t poor algorithm selection\n",
    "EDA ensured the solution was data-appropriate and scientifically justified.\n",
    "\n",
    "Lesson 2 — Performance Depends on Matching Models to Data\n",
    "This project demonstrated that:\n",
    "•\tAlgorithms like SVM and Decision Trees excel for highly categorical, non-linear data\n",
    "•\tSimpler linear models are not always the best choice\n",
    "•\tMore complex ≠ always better, but right tool for the right problem matters\n",
    "Trying multiple families of models is necessary to make an unbiased selection.\n",
    "\n",
    "Lesson 3 — Validation Is Essential for Truthful Evaluation\n",
    "Stratified cross-validation:\n",
    "-\t reduced sampling bias\n",
    "-\t made scores more generalisable\n",
    "-\thelped compare models fairly\n",
    "It reinforced the principle that a model is only as good as its evaluation strategy.\n",
    "\n",
    "The project illustrates the full lifecycle of machine learning — from understanding the data to defending a justified model choice. The major insight is that strong performance emerges from process, not luck: careful EDA + well-designed preprocessing + robust validation = trustworthy results.\n",
    "\n",
    "(182 words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
